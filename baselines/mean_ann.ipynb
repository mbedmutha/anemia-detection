{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575ff0ef",
   "metadata": {},
   "source": [
    "# Channel Mean + MLP\n",
    "\n",
    "This is an implementation of Jain et. al. on our dataset\n",
    "\n",
    "## Reference\n",
    "Jain, Prakhar, Shubham Bauskar, and Manasi Gyanchandani. \"Neural network based non‐invasive method to detect anemia from images of eye conjunctiva.\" International Journal of Imaging Systems and Technology 30.1 (2020): 112-125.\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ec1f4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_forniceal_italy.npy\") #/30\n",
    "X_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_forniceal_italy.npy\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_forniceal_india.npy\") #/30\n",
    "X_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_forniceal_india.npy\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temp\n",
    "X_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_proc_italy.npy\")/255\n",
    "X_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_proc_india.npy\")/255\n",
    "\n",
    "y_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_base_italy.npy\")\n",
    "y_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_base_india.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14579bd4",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516553a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_npy = np.concatenate((X_in, X_it), axis=0)\n",
    "y_npy = np.concatenate((y_in, y_it), axis=0)/20\n",
    "X_npy.shape, y_npy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_npy[y_npy > 0.75] = 1\n",
    "y_npy[y_npy < 1] = 0\n",
    "y_npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511229f4",
   "metadata": {},
   "source": [
    "## Channel Mean Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ee5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = X_npy[:,:,:,2].mean(axis=(1,2))\n",
    "X_g = X_npy[:,:,:,1].mean(axis=(1,2))\n",
    "X_input = np.array([X_r,  X_g]).T\n",
    "\n",
    "# X_r = X_npy[:,:,:,0].mean(axis=(1,2))\n",
    "# X_g = X_npy[:,:,:,0].mean(axis=(1,2))\n",
    "# X_input = np.array([X_r,  X_g]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[X==1] = 0\n",
    "# plt.imshow(X[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9b0ed9",
   "metadata": {},
   "source": [
    "## ANN/MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ede810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Ref: https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split=0.75\n",
    "val_split = 0.10\n",
    "test_split = 1 - train_split - val_split\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "\n",
    "# X=X[:,:,:,0]\n",
    "# X_in = torch.tensor(X).float().unsqueeze(1).float()\n",
    "X = X_input\n",
    "X_input = torch.from_numpy(X).float() #.permute(0,3,2,1)\n",
    "# X_in.shape()\n",
    "\n",
    "y_input = torch.tensor(y_npy).float().unsqueeze(1)\n",
    "\n",
    "print(X_input.shape, y_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_use, X_test, y_use,  y_test = train_test_split(X_input, y_input, test_size=test_split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_use, y_use, test_size=val_split/(val_split+train_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760edbd2",
   "metadata": {},
   "source": [
    "## Model Generation\n",
    "\n",
    "Simple model with 2-6-3-1 structure. Activation sigmoid for 0-1 outputs scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee346fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 6)\n",
    "        self.fc2 = nn.Linear(6, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a1087",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84002b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "#nn.L1Loss()\n",
    "#nn.BCEWithLogitsLoss()\n",
    "#nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "#optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#\n",
    "#\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04f5d4",
   "metadata": {},
   "source": [
    "## Minor Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.detach().numpy().flatten(), net(X_test).detach().numpy().flatten(), criterion(net(X_test), torch.Tensor(y_test)),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ff21e",
   "metadata": {},
   "source": [
    "## Full Scale Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a815a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 20\n",
    "\n",
    "# Remove later\n",
    "net = Net()\n",
    "\n",
    "net.train()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    iters = (len(X_train)//batch_size)+1\n",
    "    \n",
    "    for i in range((len(X_train)//batch_size)+1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        try:\n",
    "            inputs = X_train[(i*batch_size):(i+1)*batch_size]\n",
    "            labels = y_train[(i*batch_size):(i+1)*batch_size]\n",
    "        except:\n",
    "            inputs = X_train[(i*batch_size):]\n",
    "            labels = y_train[(i*batch_size):]\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs.shape, labels.shape, outputs.dtype, labels.dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "#     with torch.no_grad():\n",
    "    y_pred_val = net(Variable(X_val))\n",
    "    val_loss = criterion(y_pred_val, Variable(torch.Tensor(y_val)))\n",
    "    validation_loss += val_loss.item()\n",
    "    \n",
    "    if epoch %20 == 0 or epoch == epochs-1:\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / iters:.9f}, val_loss: {val_loss.item():.3f}')\n",
    "\n",
    "print(y_pred_val)\n",
    "#     running_loss = 0.0\n",
    "#     validation_loss = 0.0\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'model_weights.pth')\n",
    "# model.load_state_dict(torch.load('model_weights.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = net(X_test).detach().numpy()\n",
    "y_test = y_test.detach().numpy()\n",
    "y_hat[y_hat >= 0.75] = 0\n",
    "y_hat[y_hat > 0] = 1\n",
    "y_hat, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2211f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(1-y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat.shape, y_test.shape\n",
    "criterion(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.L1Loss()(y_hat*30, y_test*30), nn.MSELoss()(y_hat*20, y_test*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300238c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(X_test[5].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(X_test[2].permute(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1063cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(X_test)):\n",
    "#     print(f'Image: {i+1}, Hb: {y_test[i].item()}, Pred: {y_hat[i].item()}')\n",
    "#     plt.imshow(X_test[i].permute(2,1,0))\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac4e7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db58cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84761bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = reg.predict(X_val)\n",
    "y_val, y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceeaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
