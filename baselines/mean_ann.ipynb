{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575ff0ef",
   "metadata": {},
   "source": [
    "# Channel Mean + MLP\n",
    "\n",
    "This is an implementation of Jain et. al. on our dataset\n",
    "\n",
    "## Reference\n",
    "Jain, Prakhar, Shubham Bauskar, and Manasi Gyanchandani. \"Neural network based non‐invasive method to detect anemia from images of eye conjunctiva.\" International Journal of Imaging Systems and Technology 30.1 (2020): 112-125.\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ae13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c14a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ec1f4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9278852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_forniceal_italy.npy\") #/30\n",
    "X_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_forniceal_italy.npy\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cadb6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_forniceal_india.npy\") #/30\n",
    "X_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_forniceal_india.npy\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "053a63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temp\n",
    "X_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_proc_italy.npy\")/255\n",
    "X_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_proc_india.npy\")/255\n",
    "\n",
    "y_it = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_base_italy.npy\")\n",
    "y_in = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_base_india.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14579bd4",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "516553a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((212, 640, 480, 3), (212,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_npy = np.concatenate((X_in, X_it), axis=0)\n",
    "y_npy = np.concatenate((y_in, y_it), axis=0)/20\n",
    "X_npy.shape, y_npy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58ba399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_npy[y_npy > 0.75] = 1\n",
    "y_npy[y_npy < 1] = 0\n",
    "y_npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511229f4",
   "metadata": {},
   "source": [
    "## Channel Mean Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "161ee5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = X_npy[:,:,:,2].mean(axis=(1,2))\n",
    "X_g = X_npy[:,:,:,1].mean(axis=(1,2))\n",
    "X_input = np.array([X_r,  X_g]).T\n",
    "\n",
    "# X_r = X_npy[:,:,:,0].mean(axis=(1,2))\n",
    "# X_g = X_npy[:,:,:,0].mean(axis=(1,2))\n",
    "# X_input = np.array([X_r,  X_g]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb3b9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[X==1] = 0\n",
    "# plt.imshow(X[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9b0ed9",
   "metadata": {},
   "source": [
    "## ANN/MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30ede810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Ref: https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fe5de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([212, 2]) torch.Size([212, 1])\n"
     ]
    }
   ],
   "source": [
    "train_split=0.75\n",
    "val_split = 0.10\n",
    "test_split = 1 - train_split - val_split\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "\n",
    "# X=X[:,:,:,0]\n",
    "# X_in = torch.tensor(X).float().unsqueeze(1).float()\n",
    "X = X_input\n",
    "X_input = torch.from_numpy(X).float() #.permute(0,3,2,1)\n",
    "# X_in.shape()\n",
    "\n",
    "y_input = torch.tensor(y_npy).float().unsqueeze(1)\n",
    "\n",
    "print(X_input.shape, y_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b74de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_use, X_test, y_use,  y_test = train_test_split(X_input, y_input, test_size=test_split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_use, y_use, test_size=val_split/(val_split+train_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "598a322f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([158, 2]),\n",
       " torch.Size([22, 2]),\n",
       " torch.Size([32, 2]),\n",
       " torch.Size([158, 1]),\n",
       " torch.Size([22, 1]),\n",
       " torch.Size([32, 1]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760edbd2",
   "metadata": {},
   "source": [
    "## Model Generation\n",
    "\n",
    "Simple model with 2-6-3-1 structure. Activation sigmoid for 0-1 outputs scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ee346fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 6)\n",
    "        self.fc2 = nn.Linear(6, 3)\n",
    "        self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a1087",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c84002b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "#nn.L1Loss()\n",
    "#nn.BCEWithLogitsLoss()\n",
    "#nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "#optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#\n",
    "#\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04f5d4",
   "metadata": {},
   "source": [
    "## Minor Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d56aaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
       "       dtype=float32),\n",
       " array([0.43688282, 0.43689838, 0.4348906 , 0.43534613, 0.43498847,\n",
       "        0.43490046, 0.4353085 , 0.43516636, 0.43470535, 0.43501237,\n",
       "        0.43485352, 0.43469614, 0.43511823, 0.43563506, 0.4350688 ,\n",
       "        0.43519723, 0.43482712, 0.4349835 , 0.4348093 , 0.43576822,\n",
       "        0.43500304, 0.4347538 , 0.43457368, 0.43689653, 0.43458557,\n",
       "        0.4351195 , 0.43502465, 0.43519825, 0.4353249 , 0.4368975 ,\n",
       "        0.4350723 , 0.43462706], dtype=float32),\n",
       " tensor(0.6611, grad_fn=<BinaryCrossEntropyBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.detach().numpy().flatten(), net(X_test).detach().numpy().flatten(), criterion(net(X_test), torch.Tensor(y_test)),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ff21e",
   "metadata": {},
   "source": [
    "## Full Scale Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26a815a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 272.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    16] loss: 0.610886823, val_loss: 0.650\n",
      "[20,    16] loss: 0.610886823, val_loss: 0.650\n",
      "tensor([[0.4380],\n",
      "        [0.4381],\n",
      "        [0.4107],\n",
      "        [0.4381],\n",
      "        [0.4381],\n",
      "        [0.4103],\n",
      "        [0.4380],\n",
      "        [0.4379],\n",
      "        [0.4380],\n",
      "        [0.4106],\n",
      "        [0.4380],\n",
      "        [0.4101],\n",
      "        [0.4380],\n",
      "        [0.4381],\n",
      "        [0.4378],\n",
      "        [0.4108],\n",
      "        [0.4379],\n",
      "        [0.4382],\n",
      "        [0.4380],\n",
      "        [0.4363],\n",
      "        [0.4381],\n",
      "        [0.4382]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 20\n",
    "\n",
    "# Remove later\n",
    "net = Net()\n",
    "\n",
    "net.train()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    iters = (len(X_train)//batch_size)+1\n",
    "    \n",
    "    for i in range((len(X_train)//batch_size)+1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        try:\n",
    "            inputs = X_train[(i*batch_size):(i+1)*batch_size]\n",
    "            labels = y_train[(i*batch_size):(i+1)*batch_size]\n",
    "        except:\n",
    "            inputs = X_train[(i*batch_size):]\n",
    "            labels = y_train[(i*batch_size):]\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs.shape, labels.shape, outputs.dtype, labels.dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "#     with torch.no_grad():\n",
    "    y_pred_val = net(Variable(X_val))\n",
    "    val_loss = criterion(y_pred_val, Variable(torch.Tensor(y_val)))\n",
    "    validation_loss += val_loss.item()\n",
    "    \n",
    "    if epoch %20 == 0 or epoch == epochs-1:\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / iters:.9f}, val_loss: {val_loss.item():.3f}')\n",
    "\n",
    "print(y_pred_val)\n",
    "#     running_loss = 0.0\n",
    "#     validation_loss = 0.0\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2135518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'model_weights.pth')\n",
    "# model.load_state_dict(torch.load('model_weights.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53ca869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]], dtype=float32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = net(X_test).detach().numpy()\n",
    "y_test = y_test.detach().numpy()\n",
    "y_hat[y_hat >= 0.75] = 0\n",
    "y_hat[y_hat > 0] = 1\n",
    "y_hat, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e44330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db2211f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        11\n",
      "         1.0       0.66      1.00      0.79        21\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.33      0.50      0.40        32\n",
      "weighted avg       0.43      0.66      0.52        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(1-y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fe3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat.shape, y_test.shape\n",
    "criterion(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9292f615",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10300/4255056277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3218\u001b[0m             \u001b[0ml1_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3219\u001b[0m         )\n\u001b[1;32m-> 3220\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3221\u001b[0m         warnings.warn(\n\u001b[0;32m   3222\u001b[0m             \u001b[1;34m\"Using a target size ({}) that is different to the input size ({}). \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "nn.L1Loss()(y_hat*30, y_test*30), nn.MSELoss()(y_hat*20, y_test*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "300238c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5036]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X_test[5].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd52e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(X_test[2].permute(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd1063cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(X_test)):\n",
    "#     print(f'Image: {i+1}, Hb: {y_test[i].item()}, Pred: {y_hat[i].item()}')\n",
    "#     plt.imshow(X_test[i].permute(2,1,0))\n",
    "#     plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac4e7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5db58cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84761bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10300/630146045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0m\u001b[0;32m   1375\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m                              \" class: %r\" % classes_[0])\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6d75e9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = reg.predict(X_val)\n",
    "y_val, y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceeaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
