{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla CNN\n",
    "\n",
    "Code for Vanilla CNN based baseline model\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llAsTiO03Z0a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeTyQPSLBlUQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGoYgphv3gDA",
    "outputId": "aa9a7771-6dbd-4048-bec2-b608145f40a4"
   },
   "outputs": [],
   "source": [
    "path = \"/home/ssaoji/228_Project/Aug_Seg/Augmented_Segmented_data/\"#Final_Augmented_Data/\" # path to augmented data\n",
    "folders = ['Scale']#['Flip','Rotate','Scale','Translation']\n",
    "for f in folders:\n",
    "  print(len(os.listdir(path+f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFAFgfbp4-Oq"
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "      self.path = \"/home/ssaoji/228_Project/Aug_Seg/Augmented_Segmented_data/\" # path to augmented data#\"/content/drive/MyDrive/Course_files/228/dataset_anemia/Final_Augmented_Data/\" # path to augmented data\n",
    "      self.folders = ['Flip','Rotate','Scale','Translation']\n",
    "      self.y_india = pd.read_excel(r'/home/ssaoji/228_Project/dataset_anemia/India/India.xlsx')#np.load(\"/content/drive/MyDrive/Course_files/228/dataset_anemia/y_india.npy\")\n",
    "      self.y_italy = pd.read_excel(r'/home/ssaoji/228_Project/dataset_anemia/Italy/Italy_copy.xlsx')#np.load(\"/content/drive/MyDrive/Course_files/228/dataset_anemia/y_base_italy.npy\")\n",
    "      self.skip = 95 #Skip value in Italy (No value)\n",
    "      self.split = [0.8,0.1,0.1] #train,val,test\n",
    "        \n",
    "    def sample(self,num,j):\n",
    "        X = np.zeros((num,640,480,3))\n",
    "        Y = np.zeros(num)\n",
    "        seen =[]\n",
    "        for i in range(num):\n",
    "          f = np.random.randint(0,len(folders))\n",
    "          path = self.path+self.folders[f]\n",
    "          l = os.listdir(path)\n",
    "          if j ==0:\n",
    "            im_p = os.listdir(path)[0:int(len(l)*self.split[j])]\n",
    "          else:\n",
    "            im_p = os.listdir(path)[int(len(l)*self.split[j-1]):int(len(l)*self.split[j])]\n",
    "          image = random.choice(os.listdir(path))\n",
    "          name_list = image.replace(\".jpg\",\"\").split('_')\n",
    "          country = name_list[0]\n",
    "          id = int(name_list[1])\n",
    "          if country =='italy':\n",
    "            try:\n",
    "              s = d.y_italy[\"Number\"]==id\n",
    "              s[s==True].index[-1]\n",
    "              Y[i] = float(self.y_italy['Hgb'][s])/20\n",
    "            except:\n",
    "              continue\n",
    "          elif country =='india':\n",
    "            s = d.y_india[\"Number\"]==float(id)\n",
    "            s[s==True].index[-1]\n",
    "            Y[i] = float(self.y_india['Hgb'][s])/20\n",
    "            img = cv2.imread(path+'/' + image)\n",
    "            X[i,:,:,:] =  img/255\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        return X,Y\n",
    "    \n",
    "    # Generate validation samples\n",
    "    def sample_v(self,num,j):\n",
    "        X = np.zeros((num,640,480,3))\n",
    "        Y = np.zeros(num)\n",
    "        seen =[]\n",
    "        for i in range(num):\n",
    "            path = self.path+\"Scale\"\n",
    "            l = os.listdir(path)\n",
    "            im_p = os.listdir(path)[int(len(l)*self.split[j-1]):int(len(l)*self.split[j])]\n",
    "            image = random.choice(os.listdir(path))\n",
    "            name_list = image.replace(\".jpg\",\"\").split('_')\n",
    "            country = name_list[0]\n",
    "            id = int(name_list[1])\n",
    "            if country =='italy':\n",
    "                try:\n",
    "                  s = d.y_italy[\"Number\"]==id\n",
    "                  s[s==True].index[-1]\n",
    "                  Y[i] = float(self.y_italy['Hgb'][s])/20\n",
    "                except:\n",
    "                  continue\n",
    "            elif country =='india':\n",
    "                s = d.y_india[\"Number\"]==float(id)\n",
    "                s[s==True].index[-1]\n",
    "            Y[i] = float(self.y_india['Hgb'][s])/20\n",
    "            temp =cv2.imread(path+'/' + image)\n",
    "        X[i,:,:,:] =  temp/255 #cv2.cvtColor(temp, cv2.COLOR_BGR2HSV)/255\n",
    "\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2ESCFB9Ega9"
   },
   "outputs": [],
   "source": [
    "# Test loader\n",
    "d = DataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pt991ldd-_Bj"
   },
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5twZxZ_t_Tll"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(293904, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9nlLReTA-jE",
    "outputId": "20c10c12-8ce9-4f16-a8e4-f4cae6fb27a0"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# check GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGLjJaLXBFxC"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.cuda()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnZ-tGKBBLAj",
    "outputId": "78189276-1987-4734-b9f0-13120d52abdc"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "batches = 10\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"batches\" : batches\n",
    "}\n",
    "\n",
    "\n",
    "d = DataLoader()\n",
    "x,Y = d.sample_v(10,1)\n",
    "X =np.zeros((10,3,640,480))\n",
    "X[:,0,:,:] = x[:,:,:,0]\n",
    "X[:,1,:,:] = x[:,:,:,1]\n",
    "X[:,2,:,:] = x[:,:,:,2]\n",
    "y_val = torch.tensor(Y).float().unsqueeze(1).to(device)\n",
    "X_val = torch.tensor(X).float().to(device)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    # iters = (len(X_train)//batch_size)+1\n",
    "    for i in range(batches):\n",
    "        x,Y = d.sample(batch_size,0)\n",
    "        X =np.zeros((batch_size,3,640,480))\n",
    "        X[:,0,:,:] = x[:,:,:,0]\n",
    "        X[:,1,:,:] = x[:,:,:,1]\n",
    "        X[:,2,:,:] = x[:,:,:,2]\n",
    "        X=X[:,:,:]\n",
    "        inputs = torch.tensor(X).float().to(device)\n",
    "        labels = torch.tensor(Y).float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        y_pred_val = net(X_val)\n",
    "        print(y_pred_val)\n",
    "        val_loss = criterion(y_pred_val, y_val)\n",
    "        #       val_loss20 = criterion(y_pred_val*20, y_val*20)\n",
    "        validation_loss += val_loss.item()    \n",
    "        wandb.log({\"loss\": running_loss/batches,\"loss_scaled\": 400*(running_loss/batches),\"val_loss\":val_loss,\"val_loss_scaled\":val_loss*400})\n",
    "        wandb.watch(net)\n",
    "\n",
    "#       print(f'[{epoch + 1}] loss: {running_loss :.9f}, val_loss: {val_loss.item():.3f}, val_loss20: {val_loss20.item():.3f}')\n",
    "        # running_loss = 0.0\n",
    "        # validation_loss = 0.0\n",
    "        \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(net(X_val)*20)\n",
    "print(y_val*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-mx1EJjM1Ol"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GchDXRkHUrNd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnJ_46I31r9-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "data_loader.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "bf658181bf53a4bb900e3130d33239a49a3d8bc6d5119a0639656e60970d3f9f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
