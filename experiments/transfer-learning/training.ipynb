{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoQYlD7lzLXu"
   },
   "source": [
    "# Transfer Learning - I\n",
    "\n",
    "This notebook trains data from the HAM 10000 skin lesion dataset on a simple U-Net styled model. The dataset is taken from a [Kaggle Kernel](https://www.kaggle.com/alexako/cs200-1-u-net-skin-lesion-segmentation) while all processing has been done on Google Colab.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mm5kpDtpDsAo"
   },
   "outputs": [],
   "source": [
    "# Utils Imports\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tsb64shHhCM"
   },
   "outputs": [],
   "source": [
    "# Keras Imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.optimizers import adam_v2 #, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnsHwDWRH3I-"
   },
   "outputs": [],
   "source": [
    "# Notebook Support\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "# import PIL\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cv2t\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYm4d7NJ0sqG"
   },
   "source": [
    "## Colab Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHCZ35p2EH52"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnv-ODLmDtbN"
   },
   "outputs": [],
   "source": [
    "root_folder = r\"/content/drive/MyDrive/Spring 2022/Machine Learning for Physical Applications/Project/Manas Trials/Self-Supervised/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlJ6Vh3l1A2r"
   },
   "source": [
    "## Generate Training Data\n",
    "\n",
    "Images of skin and their corresponding lesion masks are taken from the dataset and loaded. This data is further used to split and create training and testing pools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "id": "6isCfN2PEUum",
    "outputId": "b0ca7b03-b490-4e8b-a182-bdcbdcc4c797"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "filelist_trainx = sorted(glob.glob(os.path.join(root_folder, \"archive/ph2_resized\", \"trainx\",\"*.bmp\"))) #, key=numericalSort\n",
    "X_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainx])\n",
    "\n",
    "filelist_trainy = sorted(glob.glob(os.path.join(root_folder, \"archive/ph2_resized\", \"trainy\",\"*.bmp\"))) # , key=numericalSort\n",
    "Y_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainy])\n",
    "\n",
    "print(filelist_trainx[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0afU7zyKIOdH"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.25, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_v2mF1e9Q-x"
   },
   "source": [
    "## Define Metrics\n",
    "\n",
    "Using Keras backend to make metrics for Intersection-over-Union, Dice, Precision, Recall and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MviLGzAUElKh"
   },
   "outputs": [],
   "source": [
    "# glob.glob(os.path.join(root_folder, \"archive/ph2_resized\", \"trainx\",\"*.bmp\"))\n",
    "def iou(y_true, y_pred, smooth = 100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2J-Yh3gE3mj"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth = 100):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tlyIzqaH7GP"
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KG-iodcyH8vF"
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Av5jBDAoH-ZJ"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''Calculates the mean accuracy rate across all predictions for binary\n",
    "    classification problems.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBna_seH9vm4"
   },
   "source": [
    "## Online Data Augmentation\n",
    "\n",
    "Data is augmented by rotation and flip at random angles and directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDnOu2vjIAJQ"
   },
   "outputs": [],
   "source": [
    "# Random Rotation\n",
    "\n",
    "def random_rotation(x_image, y_image):\n",
    "    rows_x,cols_x, chl_x = x_image.shape\n",
    "    rows_y,cols_y = y_image.shape\n",
    "    rand_num = np.random.randint(-40,40)\n",
    "    M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
    "    M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
    "    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
    "    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n",
    "    return x_image, y_image.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip Augmentation\n",
    "\n",
    "def horizontal_flip(x_image, y_image):\n",
    "    x_image = cv2.flip(x_image, 1)\n",
    "    y_image = cv2.flip(y_image.astype('float32'), 1)\n",
    "    return x_image, y_image.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDzMclzpIB_u"
   },
   "outputs": [],
   "source": [
    "# Combined Augmentation Function\n",
    "\n",
    "def img_augmentation(x_train, y_train):\n",
    "    x_rotat = []\n",
    "    y_rotat = []\n",
    "    x_flip = []\n",
    "    y_flip = []\n",
    "    x_nois = []\n",
    "    for idx in range(len(x_train)):\n",
    "        x,y = random_rotation(x_train[idx], y_train[idx])\n",
    "        x_rotat.append(x)\n",
    "        y_rotat.append(y)\n",
    "        \n",
    "        x,y = horizontal_flip(x_train[idx], y_train[idx])\n",
    "        x_flip.append(x)\n",
    "        y_flip.append(y)\n",
    "        return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXHxJ92fIFJO"
   },
   "outputs": [],
   "source": [
    "# Augmentation on data\n",
    "\n",
    "x_rotated, y_rotated, x_flipped, y_flipped = img_augmentation(x_train, y_train)\n",
    "x_rotated_t, y_rotated_t, x_flipped_t, y_flipped_t = img_augmentation(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LR4S9gxIHv_"
   },
   "outputs": [],
   "source": [
    "# Generating overall augmented dataset\n",
    "\n",
    "x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n",
    "y_train_full = np.concatenate([y_train, y_rotated, y_flipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu2AmJpv9_W1"
   },
   "outputs": [],
   "source": [
    "# Clear not needed variables from RAM\n",
    "\n",
    "del x_train\n",
    "del x_rotated\n",
    "del x_flipped\n",
    "del y_train\n",
    "del y_rotated\n",
    "del y_flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Train Test Split for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_MMDjHzIZGM"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.30, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQTsrgbMIbTz",
    "outputId": "5f60da59-6cd3-414b-821b-daad55cd28cb"
   },
   "outputs": [],
   "source": [
    "print(\"Length of the Training Set   : {}\".format(len(x_train)))\n",
    "print(\"Length of the Test Set       : {}\".format(len(x_test)))\n",
    "print(\"Length of the Validation Set : {}\".format(len(x_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrAKZuFW-yAv"
   },
   "source": [
    "## Model for Lesion Detection\n",
    "\n",
    "The model uses and encoder-bottleneck-decoder approach towards detecting lesions on the skin. Encoder and Decoder are defined separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oPOdW_DIiTB"
   },
   "outputs": [],
   "source": [
    "def encoder(img_input):\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n",
    "    x = BatchNormalization(name='bn5')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n",
    "    x = BatchNormalization(name='bn6')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n",
    "    x = BatchNormalization(name='bn7')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n",
    "    x = BatchNormalization(name='bn8')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n",
    "    x = BatchNormalization(name='bn9')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n",
    "    x = BatchNormalization(name='bn10')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n",
    "    x = BatchNormalization(name='bn11')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n",
    "    x = BatchNormalization(name='bn12')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n",
    "    x = BatchNormalization(name='bn13')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
    "    x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJDL2-edI-5h"
   },
   "outputs": [],
   "source": [
    "def decoder(enc):\n",
    "    # Decoding Layer \n",
    "    x = UpSampling2D()(enc)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n",
    "    x = BatchNormalization(name='bn14')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n",
    "    x = BatchNormalization(name='bn15')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n",
    "    x = BatchNormalization(name='bn16')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n",
    "    x = BatchNormalization(name='bn17')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n",
    "    x = BatchNormalization(name='bn18')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n",
    "    x = BatchNormalization(name='bn19')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n",
    "    x = BatchNormalization(name='bn20')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n",
    "    x = BatchNormalization(name='bn21')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n",
    "    x = BatchNormalization(name='bn22')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n",
    "    x = BatchNormalization(name='bn23')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n",
    "    x = BatchNormalization(name='bn24')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n",
    "    x = BatchNormalization(name='bn25')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n",
    "    x = BatchNormalization(name='bn26')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfKNq0JIdOJ"
   },
   "outputs": [],
   "source": [
    "def unet():\n",
    "    # Input layer\n",
    "    img_input = Input(shape= (None, None, 3))\n",
    "    \n",
    "    # Encoder bottleneck\n",
    "    enc = encoder(img_input)\n",
    "    \n",
    "    # Decoder upsampling\n",
    "    dec = decoder(enc)\n",
    "    \n",
    "    # Resampling prediction for data\n",
    "    pred = Reshape((192,256))(dec)\n",
    "    \n",
    "    # Create collective model\n",
    "    model = Model(inputs=img_input, outputs=pred)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer= adam_v2.Adam(learning_rate=0.001), loss= [\"binary_crossentropy\"]\n",
    "                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n",
    "    # , momentum=0.9, decay=0.0005, nesterov=False)\n",
    "    print(\"Model compiled successfully\") #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veyf1WrWOaQC"
   },
   "outputs": [],
   "source": [
    "# Training function that takes epochs and saves model weights\n",
    "\n",
    "def train(epochs_num, savename):\n",
    "    model = unet() #epochs_num, savename)\n",
    "    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 18, validation_data= (x_val, y_val), verbose=1)\n",
    "    model.save(savename)\n",
    "    return model,hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ti1uov0JT2A",
    "outputId": "69bca635-a561-4494-faf3-3df8be0f089a"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "base_epochs = 100\n",
    "weight_path = os.path.join(root_folder,'unet_'+str(base_epochs)+'_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2ra_4cf3EWU"
   },
   "outputs": [],
   "source": [
    "# Final training\n",
    "\n",
    "model, hist = train(base_epochs, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "We take a sample image and run entire pipeline to get a sanity check on the model and its effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_tdY03vLlPZ"
   },
   "outputs": [],
   "source": [
    "img = tf.convert_to_tensor(np.expand_dims(x_train[21],0), dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiW0CzYlJW7F"
   },
   "outputs": [],
   "source": [
    "encoded = encoder(img)\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ap416_dLr0H",
    "outputId": "38aad21a-6639-4c5e-983d-f7e12ba8bffd"
   },
   "source": [
    "### Create model and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJAGtFsjOy3B",
    "outputId": "db976a4e-de50-4816-88c7-100ca101b92b"
   },
   "outputs": [],
   "source": [
    "model0 = unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKaWLYCSOy51"
   },
   "outputs": [],
   "source": [
    "model0.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjwFbzAHPCNM",
    "outputId": "b56512aa-dd31-4b0c-e0d5-5ac57b1126a2"
   },
   "outputs": [],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4zGmeoLPCPe"
   },
   "source": [
    "### Setup model details upto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model0.predict(img)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "I_hope_this_works",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
