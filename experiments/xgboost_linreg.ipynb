{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c4fb2d",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae13f7",
   "metadata": {
    "id": "f8ae13f7"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06d8ab",
   "metadata": {
    "id": "0a06d8ab"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74649b",
   "metadata": {
    "id": "bf74649b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe5cd7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977207aa",
   "metadata": {
    "id": "977207aa"
   },
   "outputs": [],
   "source": [
    "italy_segmented_files = glob.glob(\"dataset_anemia/Italy/*/*forniceal_palpebral.png\")\n",
    "india_segmented_files = glob.glob(\"dataset_anemia/India/*/*forniceal_palpebral.png\")\n",
    "segmented_files = india_segmented_files + italy_segmented_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1be01b",
   "metadata": {
    "id": "eb1be01b",
    "outputId": "c312c359-354c-4755-96a1-005f21b5f80e"
   },
   "outputs": [],
   "source": [
    "print(india_segmented_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278852d",
   "metadata": {
    "id": "9278852d"
   },
   "outputs": [],
   "source": [
    "# y = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\y_base_italy.npy\") #/30\n",
    "# X = np.load(r\"C:\\Users\\manas\\Documents\\Winter 2022\\Digital Health Systems\\Project\\anemia_detection\\X_base_italy.npy\")/255\n",
    "yit = np.load(r\"y_base_italy.npy\")\n",
    "# x = np.load(r\"/content/X_new.npy\")/255\n",
    "x = np.load(r\"X_new_RGB.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d714c871",
   "metadata": {
    "id": "d714c871"
   },
   "outputs": [],
   "source": [
    "yin = np.load(r\"y_india.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9768993",
   "metadata": {
    "id": "f9768993",
    "outputId": "ee9d388e-1214-4d37-a4c0-118250e90fa7"
   },
   "outputs": [],
   "source": [
    "yin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76be731",
   "metadata": {
    "id": "a76be731",
    "outputId": "9f7b784d-7631-4953-812a-83e35f6e223c"
   },
   "outputs": [],
   "source": [
    "y = np.concatenate((yit , yin))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372b9c7",
   "metadata": {
    "id": "4372b9c7",
    "outputId": "f55ccd1b-a585-4e7e-9044-438791a9dc81"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d052b2f",
   "metadata": {},
   "source": [
    "## Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36496e",
   "metadata": {
    "id": "2f36496e"
   },
   "outputs": [],
   "source": [
    "Folder_name = \"dataset_anemia/Seg_task_data\"\n",
    "Extension=\".jpg\"\n",
    "\n",
    "def scale_image(image,name):\n",
    "    image = cv2.resize(image,(480,640), interpolation = cv2.INTER_CUBIC)\n",
    "    l = name.split(\"/\")\n",
    "    #cv2.imwrite(Folder_name+\"/Scale/\"+'india_'+l[2]+Extension, image)\n",
    "    return image\n",
    "\n",
    "def scale_image_or(image,name):\n",
    "    image = cv2.resize(image,(480,640), interpolation = cv2.INTER_CUBIC)\n",
    "    l = name.split(\"/\")\n",
    "    #cv2.imwrite(Folder_name+\"/Scale/\"+'india_'+l[2]+Extension, image)\n",
    "    return image\n",
    "def scale_image_seg(image,name):\n",
    "    image = cv2.resize(image,(480,640), interpolation = cv2.INTER_CUBIC)\n",
    "    l = name.split(\"/\")\n",
    "    #cv2.imwrite(Folder_name+\"/Scale/\"+'india_'+l[2]+Extension, image)\n",
    "    return image\n",
    "\n",
    "def translation_image(image,x,y,name):\n",
    "    rows, cols ,c= image.shape\n",
    "    M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "    image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    l = name.split(\"/\")\n",
    "    return image\n",
    "    #cv2.imwrite(Folder_name + \"/Translation/\"+'india_'+l[2]+\"_\"+ str(x) + str(y) + Extension, image)\n",
    "\n",
    "def rotate_image(image,deg,name):\n",
    "    rows, cols,c = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), deg, 1)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    l = name.split(\"/\")\n",
    "    return image\n",
    "    #cv2.imwrite(Folder_name + \"/Rotate/\"+'india_'+l[2]+\"_\"+str(deg) + Extension, image)\n",
    "\n",
    "def flip_image(image,name):\n",
    "    imageh = cv2.flip(image, 0)\n",
    "    imagev = cv2.flip(image, 1)\n",
    "    l = name.split(\"/\")\n",
    "    return imageh,imagev\n",
    "    #cv2.imwrite(Folder_name + \"/Flip/\"+'india_'+l[2]+ \"_\"+str(0)+Extension, imageh)\n",
    "    #cv2.imwrite(Folder_name + \"/Flip/\"+'india_'+l[2]+ \"_\"+str(1)+Extension, imagev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171e699",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc574f22",
   "metadata": {
    "id": "bc574f22"
   },
   "outputs": [],
   "source": [
    "x_aug_it = []\n",
    "y_aug_it = []\n",
    "for a in range(x.shape[0]):\n",
    "    i = x[a]\n",
    "    filename = 'a'\n",
    "    x_aug_it.append(i)\n",
    "    y_aug_it.append(yit[a])\n",
    "\n",
    "    x_aug_it.append(translation_image(i,50,50,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(translation_image(i,-50,50,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(translation_image(i,50,-50,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(translation_image(i,-50,-50,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "\n",
    "    x_aug_it.append(rotate_image(i,45,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(rotate_image(i,90,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(rotate_image(i,135,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(rotate_image(i,180,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(rotate_image(i,225,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(rotate_image(i,270,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(rotate_image(i,315,filename))\n",
    "    y_aug_it.append(yit[a])\n",
    "\n",
    "    x_aug_it.append(flip_image(i,filename)[0])\n",
    "    y_aug_it.append(yit[a])\n",
    "    x_aug_it.append(flip_image(i,filename)[1])\n",
    "    y_aug_it.append(yit[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ab71f",
   "metadata": {
    "id": "084ab71f",
    "outputId": "82eb4fb3-6728-4f52-cad3-db6b76655274"
   },
   "outputs": [],
   "source": [
    "x_aug_it = np.array(x_aug_it)\n",
    "x_aug_it.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a2d9c",
   "metadata": {
    "id": "1b8a2d9c",
    "outputId": "8b2ccfa1-baca-487d-a51e-38ceeb525ca3"
   },
   "outputs": [],
   "source": [
    "y_aug_it = np.array(y_aug_it)\n",
    "y_aug_it.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abd6ec",
   "metadata": {
    "id": "58abd6ec"
   },
   "outputs": [],
   "source": [
    "x_aug_it = x_aug_it/255\n",
    "y_aug_it = y_aug_it/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46071ef8",
   "metadata": {
    "id": "46071ef8",
    "outputId": "84e50043-a430-4522-8d50-11a1d7a17e3f"
   },
   "outputs": [],
   "source": [
    "#for U net\n",
    "for i in india_segmented_files:\n",
    "    im = cv2.imread(i)\n",
    "    \n",
    "    l = i.split(\"/\")\n",
    "    filename = i\n",
    "    \n",
    "    image=scale_image(im,filename)\n",
    "    path_folder = \"/\".join(l[:3])+\"/*.jpg\"\n",
    "    file = glob.glob(path_folder)\n",
    "\n",
    "    orig_im=cv2.imread(file[0])\n",
    "    plt.imshow(im)\n",
    "    plt.imshow(orig_im)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485603c",
   "metadata": {
    "id": "d485603c",
    "outputId": "4e4f9544-7ade-449e-b97e-badcb0a83fd6"
   },
   "outputs": [],
   "source": [
    "#augmentation\n",
    "for i in india_segmented_files:\n",
    "    im = cv2.imread(i)\n",
    "    xc, yc = np.nonzero(im[:,:,0])\n",
    "    xl,xr = xc.min(),xc.max()\n",
    "    yl,yr = yc.min(),yc.max()\n",
    "    im = im[xl:xr+1, yl:yr+1,:]\n",
    "    \n",
    "    l = i.split(\"/\")\n",
    "    filename = i\n",
    "    \n",
    "    image=scale_image(im,filename)\n",
    "\n",
    "    translation_image(image,50,50,filename)\n",
    "    translation_image(image,-50,50,filename)\n",
    "    translation_image(image,50,-50,filename)\n",
    "    translation_image(image,-50,-50,filename)\n",
    "\n",
    "    rotate_image(image,45,filename)\n",
    "    rotate_image(image,90,filename)\n",
    "    rotate_image(image,135,filename)\n",
    "    rotate_image(image,180,filename)\n",
    "    rotate_image(image,225,filename)\n",
    "    rotate_image(image,270,filename)\n",
    "    rotate_image(image,315,filename)\n",
    "\n",
    "    flip_image(image,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab521c24",
   "metadata": {
    "id": "ab521c24",
    "outputId": "9d448abf-bd5c-40dd-81f2-f75c4cf00588"
   },
   "outputs": [],
   "source": [
    "x_seg=[]\n",
    "y_seg=[]\n",
    "for i in italy_segmented_files:\n",
    "    im = cv2.imread(i)\n",
    "    xc, yc = np.nonzero(im[:,:,0])\n",
    "    xl,xr = xc.min(),xc.max()\n",
    "    yl,yr = yc.min(),yc.max()\n",
    "    im = im[xl:xr+1, yl:yr+1,:]\n",
    "    x_seg.append(cv2.resize(im,(480,640)))\n",
    "    l = i.split(\"/\")\n",
    "    y_seg.append(yit[int(l[2])-1])\n",
    "\n",
    "for i in india_segmented_files:\n",
    "    im = cv2.imread(i)\n",
    "    xc, yc = np.nonzero(im[:,:,0])\n",
    "    xl,xr = xc.min(),xc.max()\n",
    "    yl,yr = yc.min(),yc.max()\n",
    "    im = im[xl:xr+1, yl:yr+1,:]\n",
    "    x_seg.append(cv2.resize(im,(480,640)))\n",
    "    l = i.split(\"/\")\n",
    "    y_seg.append(yin[int(l[2])-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbe548",
   "metadata": {
    "id": "d9fbe548"
   },
   "outputs": [],
   "source": [
    "x_seg = np.array(x_seg)\n",
    "y_seg = np.array(y_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc6408",
   "metadata": {
    "id": "82fc6408",
    "outputId": "18eb65d9-b88b-441e-bdd4-9645d9cdc026"
   },
   "outputs": [],
   "source": [
    "x_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a5bb5",
   "metadata": {
    "id": "132a5bb5",
    "outputId": "b0660c09-c3f3-4b17-8b71-64997cd48636"
   },
   "outputs": [],
   "source": [
    "y_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ffe8c",
   "metadata": {
    "id": "833ffe8c",
    "outputId": "fd67033b-9617-47b5-e012-5b741402966f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_seg[1][:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ded888",
   "metadata": {
    "id": "b5ded888"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"dataset_anemia/Italy/Italy.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950deb0",
   "metadata": {
    "id": "6950deb0",
    "outputId": "407b43a0-82d8-4666-e7bd-269584496d29"
   },
   "outputs": [],
   "source": [
    "data['Hgb'].isna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1f3e2",
   "metadata": {
    "id": "0bf1f3e2",
    "outputId": "2a53087a-1464-459c-dcaa-aabc481eaea2"
   },
   "outputs": [],
   "source": [
    "Age = data['Age'].astype(np.float32)\n",
    "Hgb = data['Hgb'].astype(np.float32)\n",
    "plt.scatter(Age,Hgb)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Hgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a71b33",
   "metadata": {
    "id": "14a71b33",
    "outputId": "8956fe91-c7f3-4e25-ce37-20888983daab"
   },
   "outputs": [],
   "source": [
    "gender = data['Gender']\n",
    "Hgb = data['Hgb'].astype(np.float32)\n",
    "plt.bar(gender,Hgb)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Hgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee184e02",
   "metadata": {
    "id": "ee184e02",
    "outputId": "1a3fcc50-7d79-4753-ff09-acd914944502"
   },
   "outputs": [],
   "source": [
    "print('No. of samples = ', y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970eed5",
   "metadata": {
    "id": "f970eed5"
   },
   "outputs": [],
   "source": [
    "x_seg = x_seg/255\n",
    "y_seg = y_seg/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180b944",
   "metadata": {
    "id": "9180b944",
    "outputId": "be4f6196-a853-4b37-9e6a-d27aa6aef7d5"
   },
   "outputs": [],
   "source": [
    "x_aug_it.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ivH1MFxL9M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "27ivH1MFxL9M",
    "outputId": "e54b6fce-9156-4a5c-cbeb-dff1e2aea4b2"
   },
   "outputs": [],
   "source": [
    "X =np.zeros((1722,3,640,480))\n",
    "X[:,0,:,:] = x_aug_it[:,:,:,0]\n",
    "X[:,1,:,:] = x_aug_it[:,:,:,1]\n",
    "X[:,2,:,:] = x_aug_it[:,:,:,2]\n",
    "X.shape\n",
    "plt.imshow(x_aug_it[0,:,:,:])\n",
    "\n",
    "X[0,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cee803",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfcfd4",
   "metadata": {
    "id": "febfcfd4"
   },
   "outputs": [],
   "source": [
    "train_split=0.9\n",
    "val_split = 0.05\n",
    "test_split = 1 - train_split - val_split\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "\n",
    "X=X[:,:,:]\n",
    "X_in = torch.tensor(X).float()\n",
    "X_in.size()\n",
    "\n",
    "y_in = torch.tensor(y_seg).float().unsqueeze(1)\n",
    "\n",
    "print(X_in.shape, y_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3db582",
   "metadata": {
    "id": "1c3db582"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_use, X_test, y_use,  y_test = train_test_split(X_in, y_in, test_size=test_split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_use, y_use, test_size=val_split/(val_split+train_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6477e5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6477e5e",
    "outputId": "33bce43b-b741-4f01-b0a6-8e3ad3a0ed19"
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8d53c",
   "metadata": {
    "id": "27d8d53c"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# criterion = nn.MSELoss\n",
    "# #nn.BCEWithLogitsLoss()\n",
    "# #nn.BCELoss()\n",
    "# #nn.MSELoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "# #optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bb509",
   "metadata": {
    "id": "8d4bb509"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(293904, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jhalu-IlBZuV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhalu-IlBZuV",
    "outputId": "142d335e-5491-4f5e-992a-a606bddf9854"
   },
   "outputs": [],
   "source": [
    "# check GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6f8c3",
   "metadata": {
    "id": "41a6f8c3"
   },
   "outputs": [],
   "source": [
    "y_test \n",
    "# net(X_test)\n",
    "# criterion(net(X_test), torch.Tensor(y_test))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a815a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26a815a8",
    "outputId": "50b801a7-5a9a-4fbd-842a-a9fc5b5d8f29"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 4\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    iters = (len(X_train)//batch_size)+1\n",
    "    \n",
    "    for i in range((len(X_train)//batch_size)+1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        try:\n",
    "            inputs = X_train[(i*batch_size):(i+1)*batch_size]\n",
    "            labels = y_train[(i*batch_size):(i+1)*batch_size]\n",
    "        except:\n",
    "            inputs = X_train[(i*batch_size):]\n",
    "            labels = y_train[(i*batch_size):]\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs.shape, labels.shape, outputs.dtype, labels.dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        y_pred_val = net(X_val)\n",
    "        val_loss = criterion(y_pred_val, torch.Tensor(y_val))\n",
    "        validation_loss += val_loss.item()\n",
    "        \n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / iters:.9f}, val_loss: {val_loss.item():.3f}')\n",
    "    # running_loss = 0.0\n",
    "    # validation_loss = 0.0\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2135518f",
   "metadata": {
    "id": "2135518f",
    "outputId": "b8ca0e53-b5e8-4e2e-f8a0-43ce916ec389"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'seg_vcnn_model_weights.pth')\n",
    "net.load_state_dict(torch.load('seg_vcnn_model_weights.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf8f56",
   "metadata": {
    "id": "29cf8f56"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca869d",
   "metadata": {
    "id": "53ca869d",
    "outputId": "94fb3a77-19b1-4a52-ff98-4f0d62b31ce9"
   },
   "outputs": [],
   "source": [
    "#MSE\n",
    "mean_squared_error( (net(X_test)).detach()*20 , y_test*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27710e3",
   "metadata": {
    "id": "e27710e3"
   },
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 5)\n",
    "        self.fc1 = nn.Linear(293904, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.bn(x)\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.bn(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net2 = Net2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5293c",
   "metadata": {
    "id": "40c5293c"
   },
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950f39f",
   "metadata": {
    "id": "e950f39f",
    "outputId": "86e9a545-1fa3-40e8-9847-20a50c45d09f"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(net2,(3,640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b28b66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0b28b66",
    "outputId": "5e71584b-40eb-4df5-b961-314b04f83db2"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 4\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    iters = (len(X_train)//batch_size)+1\n",
    "    \n",
    "    for i in range((len(X_train)//batch_size)+1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        try:\n",
    "            inputs = X_train[(i*batch_size):(i+1)*batch_size]\n",
    "            labels = y_train[(i*batch_size):(i+1)*batch_size]\n",
    "        except:\n",
    "            inputs = X_train[(i*batch_size):]\n",
    "            labels = y_train[(i*batch_size):]\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net2(inputs)\n",
    "#         print(outputs.shape, labels.shape, outputs.dtype, labels.dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        y_pred_val = net2(X_val)\n",
    "        # print(y_pred_val)\n",
    "        val_loss = criterion(y_pred_val, torch.Tensor(y_val))\n",
    "        validation_loss += val_loss.item()\n",
    "        \n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / iters:.9f}, val_loss: {val_loss.item():.3f}')\n",
    "    # running_loss = 0.0\n",
    "    # validation_loss = 0.0\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uAOg6jF_ekCN",
   "metadata": {
    "id": "uAOg6jF_ekCN",
    "outputId": "c1148f51-0041-491f-e61c-067710b4b2b4"
   },
   "outputs": [],
   "source": [
    "#MSE\n",
    "mean_squared_error( (net2(X_test)).detach()*20 , y_test*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb91e06",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc225b",
   "metadata": {
    "id": "39cc225b",
    "outputId": "25e2a9c7-0a40-4d94-fc0e-6520193d35f3"
   },
   "outputs": [],
   "source": [
    "# Import the packages and classes needed for this example:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "'''y = np.load(r\"y_base_italy.npy\")\n",
    "x = np.load(r\"X_new_RGB.npy\")/255'''\n",
    "\n",
    "X = np.ones((211,307200))\n",
    "for i in range(211):\n",
    "  X[i] = x_seg[i,:,:,0].flatten()\n",
    "X.shape,y_seg.shape\n",
    "\n",
    "# # Create a linear regression model based the positioning of the data and Intercept, and predict a Best Fit:\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X[:200], y_seg[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c02f0c",
   "metadata": {
    "id": "34c02f0c",
    "outputId": "d2088216-804e-440b-fe63-1334c000fe7a"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X[200:])\n",
    "mean_squared_error( preds*20 , y_seg[200:]*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fa3e2",
   "metadata": {
    "id": "4a5fa3e2",
    "outputId": "deb1086a-35ca-4d81-d9f9-4f103eaa857c"
   },
   "outputs": [],
   "source": [
    "X = np.ones((211,307200))\n",
    "for i in range(211):\n",
    "  X[i] = x_seg[i,:,:,1].flatten()\n",
    "X.shape,y_seg.shape\n",
    "\n",
    "# # Create a linear regression model based the positioning of the data and Intercept, and predict a Best Fit:\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X[:200], y_seg[:200])\n",
    "\n",
    "preds = model.predict(X[200:])\n",
    "mean_squared_error( preds*20 , y_seg[200:]*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c203259",
   "metadata": {
    "id": "2c203259",
    "outputId": "b9d6618b-ac6f-4c9e-c1d0-4686a678db40"
   },
   "outputs": [],
   "source": [
    "X = np.ones((211,307200))\n",
    "for i in range(211):\n",
    "  X[i] = x_seg[i,:,:,2].flatten()\n",
    "X.shape,y_seg.shape\n",
    "\n",
    "# # Create a linear regression model based the positioning of the data and Intercept, and predict a Best Fit:\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X[:200], y_seg[:200])\n",
    "\n",
    "preds = model.predict(X[200:])\n",
    "mean_squared_error( preds*20 , y_seg[200:]*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727fc316",
   "metadata": {
    "id": "727fc316",
    "outputId": "16c0e59a-3664-4c0c-ab0e-562ec4fc665a"
   },
   "outputs": [],
   "source": [
    "X = np.ones((211,921600))\n",
    "for i in range(211):\n",
    "  X[i] = x_seg[i,:,:,:].flatten()\n",
    "X.shape,y_seg.shape\n",
    "\n",
    "# # Create a linear regression model based the positioning of the data and Intercept, and predict a Best Fit:\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X[:200], y_seg[:200])\n",
    "\n",
    "preds = model.predict(X[200:])\n",
    "mean_squared_error( preds*20 , y_seg[200:]*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553089f",
   "metadata": {
    "id": "8553089f",
    "outputId": "d4a1334e-6d99-4f4b-cbe5-5ec4ef34858b"
   },
   "outputs": [],
   "source": [
    "y_seg[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598a40a",
   "metadata": {
    "id": "8598a40a",
    "outputId": "d959177f-a0e9-4121-c7b2-d98f1fd57d42"
   },
   "outputs": [],
   "source": [
    "preds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d08b9e",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808f185",
   "metadata": {
    "id": "5808f185",
    "outputId": "8a04f2aa-4b97-4781-c9f4-290587845dd0"
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(n_estimators=10, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "model.fit(X[:110], y_seg[:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b0062",
   "metadata": {
    "id": "a84b0062",
    "outputId": "da7a3334-ae6c-4fe7-c904-48e84d70edec"
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = model.predict(X[:20])\n",
    "mean_squared_error( preds*20 , y_seg[:20]*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6607e",
   "metadata": {
    "id": "45a6607e",
    "outputId": "689fc8f2-a3a0-44ea-db27-55020a95947c"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b65ba6",
   "metadata": {
    "id": "e7b65ba6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Segmented_data_Trial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
